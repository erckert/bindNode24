{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d89031-a101-4264-abef-1a30e3d183df",
   "metadata": {},
   "source": [
    "### Enter your fasta file path and prediction folder path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da5cb4a-1a41-4adc-b48a-e2d61eac96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_folder = \"\" #TODO\n",
    "query_fasta = \"\" #TODO\n",
    "embedding_batchsize = 30 #TODO. Decrease in case of CUDA-Out-Of-Memory errors<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035e5eae-8a70-4e9e-a9c6-7a7c58518700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/gcn/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from config import FileSetter, FileManager\n",
    "from bindNode23.bindNode23 import BindNode23\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from transformers import T5Tokenizer, T5Model, T5EncoderModel\n",
    "import re\n",
    "import torch\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import config\n",
    "import bindNode23.bindNode23\n",
    "from config import FileSetter, FileManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26355660-c4d3-4839-9c89-a9e7fd53f028",
   "metadata": {},
   "source": [
    "##### This code box sets up the protein language model ProtT5. Could trigger CUDA-errors on machines with less than 4GB (NVIDIA) GPU VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9f2ade-2728-42b8-b49d-7075636b1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a58a27-f2a1-484f-bf35-976abbf8ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse fasta file, space and substitute unknown AAs, tokenize\n",
    "query_sequences = FileManager.read_fasta(query_fasta)\n",
    "sequences = query_sequences.values()\n",
    "headers = query_sequences.keys()\n",
    "sequences = [\" \".join(sequence) for sequence in sequences]\n",
    "sequences = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences]\n",
    "ids = tokenizer.batch_encode_plus(sequences, add_special_tokens=True, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3e2be-7755-4de1-b984-2becfbea60a5",
   "metadata": {},
   "source": [
    "##### Embed the sequences in your fasta file. If you encouter CUDA-Out-Of-Memory warnings, consider using a lower batchsize in top cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f70b8f-c56c-4d81-b319-536efd5215f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [00:35<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making file...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "bsize = embedding_batchsize\n",
    "maxsize = len(sequences)\n",
    "start = 0\n",
    "end = bsize\n",
    "features = []\n",
    "\n",
    "for i in tqdm(range(bsize, maxsize, bsize)):\n",
    "    start = i - bsize\n",
    "    end = i\n",
    "    batch_ids = ids.input_ids[start:end]\n",
    "    batch_masks = ids.attention_mask[start:end]\n",
    "    input_ids = torch.tensor(batch_ids).to(device)\n",
    "    attention_mask = torch.tensor(batch_masks).to(device)\n",
    "    with torch.no_grad():\n",
    "      embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
    "    for e in embedding:\n",
    "      features.append(e)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# Add last batch\n",
    "batch_ids = ids.input_ids[end:]\n",
    "batch_masks = ids.attention_mask[end:]\n",
    "input_ids = torch.tensor(batch_ids).to(device)\n",
    "attention_mask = torch.tensor(batch_masks).to(device)\n",
    "with torch.no_grad():\n",
    "  embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "embedding = embedding.last_hidden_state.cpu().numpy()\n",
    "for e in embedding:\n",
    "  features.append(e)\n",
    "\n",
    "# sanity check for the created data\n",
    "assert len(features)==len(sequences)\n",
    "\n",
    "print(\"Making file...\")\n",
    "h5f = h5py.File(os.path.join(prediction_folder, 'embeddings_halfprec_inference.h5'), 'w')\n",
    "for i,header in enumerate(headers):\n",
    "  h5f.create_dataset(header, data=features[i][:len(query_sequences[header])])\n",
    "h5f.close()\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fa57a-52cc-41ee-8dd6-71ac5ef6e55e",
   "metadata": {},
   "source": [
    "##### now, there is an .h5 file created in your prediction directory. We will use it to predict your proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa0f062-5f84-493f-9c0c-c95a40455a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data\n",
      "Load model\n",
      "Calculate predictions\n",
      "Load model\n",
      "Calculate predictions\n",
      "Load model\n",
      "Calculate predictions\n",
      "Load model\n",
      "Calculate predictions\n",
      "Load model\n",
      "Calculate predictions\n"
     ]
    }
   ],
   "source": [
    "model_prefix=\"trained_models/trained_model\"\n",
    "cutoff=0.5\n",
    "ri=False\n",
    "result_folder=prediction_folder\n",
    "ids = list(headers)\n",
    "fasta_file=query_fasta\n",
    "\n",
    "proteins = BindNode23.GCN_prediction_pipeline(\n",
    "   os.path.join(prediction_folder, 'embeddings_halfprec_inference.h5'), model_prefix, cutoff, result_folder, ids, fasta_file, ri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2b3fb-ec95-48b6-a66a-d401e28802f9",
   "metadata": {},
   "source": [
    "#### For each protein, you will yield an output file (.bindPredict_out) with the following content:\n",
    "##### Binding prediction (b/nb), respective probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6c73527-8f07-4a8a-9f14-a47809e0ae6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein name:\n",
      "\n",
      "P32643 \n",
      "\n",
      "Position\tMetal.Proba\tMetal.Class\tNuclear.Proba\tNuclear.Class\tSmall.Proba\tSmall.Class\tAny.Class\n",
      "\n",
      "1\t\t0.002\t\tnb\t\t0.004\t\tnb\t\t0.077\t\tnb\t\tnb\n",
      "\n",
      "2\t\t0.009\t\tnb\t\t0.012\t\tnb\t\t0.354\t\tnb\t\tnb\n",
      "\n",
      "3\t\t0.029\t\tnb\t\t0.037\t\tnb\t\t0.328\t\tnb\t\tnb\n",
      "\n",
      "4\t\t0.021\t\tnb\t\t0.014\t\tnb\t\t0.428\t\tnb\t\tnb\n",
      "\n",
      "5\t\t0.005\t\tnb\t\t0.010\t\tnb\t\t0.206\t\tnb\t\tnb\n",
      "\n",
      "6\t\t0.009\t\tnb\t\t0.016\t\tnb\t\t0.277\t\tnb\t\tnb\n",
      "\n",
      "7\t\t0.011\t\tnb\t\t0.032\t\tnb\t\t0.172\t\tnb\t\tnb\n",
      "\n",
      "8\t\t0.100\t\tnb\t\t0.006\t\tnb\t\t0.332\t\tnb\t\tnb\n",
      "\n",
      "9\t\t0.046\t\tnb\t\t0.009\t\tnb\t\t0.566\t\tb\t\tb\n",
      "\n",
      "10\t\t0.038\t\tnb\t\t0.003\t\tnb\t\t0.223\t\tnb\t\tnb\n",
      "\n",
      "11\t\t0.047\t\tnb\t\t0.009\t\tnb\t\t0.280\t\tnb\t\tnb\n",
      "\n",
      "12\t\t0.048\t\tnb\t\t0.001\t\tnb\t\t0.112\t\tnb\t\tnb\n",
      "\n",
      "13\t\t0.022\t\tnb\t\t0.014\t\tnb\t\t0.286\t\tnb\t\tnb\n",
      "\n",
      "14\t\t0.124\t\tnb\t\t0.023\t\tnb\t\t0.633\t\tb\t\tb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allpredictionfiles = list(Path(prediction_folder).rglob(\"*.bindPredict_out\"))\n",
    "with open(allpredictionfiles[0], 'r') as displayFile:\n",
    "    results = displayFile.readlines()\n",
    "    \n",
    "print(\"Protein name:\\n\")\n",
    "print(allpredictionfiles[0].name.split(\".\")[0], '\\n')\n",
    "print(results[0])\n",
    "for k in range(1,15):\n",
    "    print(results[k].replace('\\t', '\\t\\t'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
