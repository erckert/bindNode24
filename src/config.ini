[DEFAULT]
# mode sets the mode in which the model is run. Valid modes are: [optimize-architecture, training, testing].
# optimize-architecture: hyperparameter tuning during model training
# training: Train a single model with specified parameters. If multiple are given in this config file, the first one will be selected
# predict: load a pretrained model and only run predictions
mode = training

[FILE_PATHS]
# result dir defines the directory in which the result files will be stored. If the directory doesn't exist it will be created
result_dir = Path\to\folder\for\output
# embeddings sets the file path to the embedding file.
# Embeddings need to be provided as h5 file with identifier that match the identifiers in the fasta file exactly
embeddings = path\to\h5\embedding\file
# id_list sets the file path to the txt file that contains the subset of IDs, which should be used
id_list = path\to\protein\id\file
# cv_split_id_files_folder sets the file path to the folder containing files with the ids for the individual cross-validation splits
cv_split_id_files_folder = path\to\CV\files\folder
# 3d_structure_dir sets the file path to the folder containing the 3D protein structures as .pdb files.
# File names in this directory have to match the identifiers given in the fasta file exactly.
3d_structure_dir = path\to\predicted\3D\structure\folder
# precomputed_DSSP_feature_dir sets the file path to the folder containing the precomputed DSSP features in CSV format.
# File names in this directory have to match the identifiers given in the fasta file exactly.
precomputed_DSSP_feature_dir = path\to\precomputed\DSSP\file\folder
# fasta_file_path sets the file path to the fasta fie that contains the amino acid sequences.
# The sequences need to be the same as were used for embedding creations. Any differences, especially in protein length
# may cause a crash of this program
fasta_file_path = path\to\fasta\file
# cache_folder sets the file path to the folder that should be used as cache. The folder will be created if it doesn't
# already exist. Will only be used if use_cache is set to true
cache_folder =  path\to\cache\folder

[LABELS]

# IDs in the labels files need to match fasta sequence identifiers exactly
metal_label_file = ..\dataset\binding_residues_2.5_metal.txt
small_label_file = ..\dataset\binding_residues_2.5_small.txt
nuclear_label_file = ..\dataset\binding_residues_2.5_nuclear.txt

[UTILITY]
# do_logging turns logging on/off
do_logging = yes
# use cache to e.g. store and load precomputed distance matrices instead of recomputing them each run
use_cache = True

[MODEL]
# weight folder specifies the folder where trained models will be safed after training or from where model weights will be loaded
weight_folder = path\to\model\weights\folder
# model type specifies which model architecture should be used. Valid types are: [GCNConv, SAGEConv, SAGEConvMLP, SAGEConvGATMLP].
model_type = SAGEConv
# Predictions above this cutoff will be considered as the model predicting the residue as binding.
cutoff = 0.5
# usually the size of the used embeddings, in case of ProtT5 this should be 1024
in_channels = 1024
# nr of features that should be used additionally to the embeddings, e.g. normalized DSSP features.
nr_additional_features = 20
# use_dssp turns using dssp features for model training/ prediction on/off (WARNING: a model trained with dssp features
# will always need them for downstream predictions as well and a model trained without cannot suddenly use them!)
use_dssp = False
# nr of prediction classes for the output. By default this should be 3 for metal, nuclear or small.
# A residue is considered to be generally binding if any of the values in the output vector is above the cutoff
out_channels = 3

[DATASET]
# distance cutoff in Armstrong for connectivity graph of proteins.
# To only use the backbone of a protein, set this value to ~4
cutoff_structure: 17

[OUTPUT]
# write_ri determines if the output file will contain the reliability index (True) or raw probabilities (False).
write_ri = False

[MODEL_PARAMETERS]
features = 128
dropout = 0.7
epochs = 100
early_stopping = True
activation = F.leaky_relu
batchsize = 406
dropout_fcn = 0.8

[LOSS_FUNCTION_PARAMETERS]
weights: [8.9, 7.7, 4.4]

[OPTIMIZER_PARAMETERS]
# learning rate
learning_rate = 0.01
betas = [0.9, 0.999]
epsilon = 1e-8
weight_decay = 0.0