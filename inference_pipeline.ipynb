{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d89031-a101-4264-abef-1a30e3d183df",
   "metadata": {},
   "source": [
    "### Enter your fasta file path and prediction folder path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da5cb4a-1a41-4adc-b48a-e2d61eac96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_folder = \"/home/frank/bind/bindPredict/jupyterpred\" #TODO\n",
    "query_fasta = \"/home/frank/bind/bindPredict/data/development_set/all.fasta\" #TODO\n",
    "embedding_batchsize = 30 #TODO. Decrease in case of CUDA-Out-Of-Memory errors<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035e5eae-8a70-4e9e-a9c6-7a7c58518700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda2/envs/gcn/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from config import FileSetter, FileManager\n",
    "from bindNode23.bindNode23 import BindNode23\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from transformers import T5Tokenizer, T5Model, T5EncoderModel\n",
    "import re\n",
    "import torch\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import config\n",
    "import bindNode23.bindNode23\n",
    "from config import FileSetter, FileManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26355660-c4d3-4839-9c89-a9e7fd53f028",
   "metadata": {},
   "source": [
    "##### This code box sets up the protein language model ProtT5. Could trigger CUDA-errors on machines with less than 4GB (NVIDIA) GPU VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9f2ade-2728-42b8-b49d-7075636b1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a58a27-f2a1-484f-bf35-976abbf8ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse fasta file, space and substitute unknown AAs, tokenize\n",
    "query_sequences = FileManager.read_fasta(query_fasta)\n",
    "sequences = query_sequences.values()\n",
    "headers = query_sequences.keys()\n",
    "sequences = [\" \".join(sequence) for sequence in sequences]\n",
    "sequences = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences]\n",
    "ids = tokenizer.batch_encode_plus(sequences, add_special_tokens=True, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3e2be-7755-4de1-b984-2becfbea60a5",
   "metadata": {},
   "source": [
    "##### Embed the sequences in your fasta file. If you encouter CUDA-Out-Of-Memory warnings, consider using a lower batchsize in top cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f70b8f-c56c-4d81-b319-536efd5215f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [00:35<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making file...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "bsize = embedding_batchsize\n",
    "maxsize = len(sequences)\n",
    "start = 0\n",
    "end = bsize\n",
    "features = []\n",
    "\n",
    "for i in tqdm(range(bsize, maxsize, bsize)):\n",
    "    start = i - bsize\n",
    "    end = i\n",
    "    batch_ids = ids.input_ids[start:end]\n",
    "    batch_masks = ids.attention_mask[start:end]\n",
    "    input_ids = torch.tensor(batch_ids).to(device)\n",
    "    attention_mask = torch.tensor(batch_masks).to(device)\n",
    "    with torch.no_grad():\n",
    "      embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
    "    for e in embedding:\n",
    "      features.append(e)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# Add last batch\n",
    "batch_ids = ids.input_ids[end:]\n",
    "batch_masks = ids.attention_mask[end:]\n",
    "input_ids = torch.tensor(batch_ids).to(device)\n",
    "attention_mask = torch.tensor(batch_masks).to(device)\n",
    "with torch.no_grad():\n",
    "  embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "embedding = embedding.last_hidden_state.cpu().numpy()\n",
    "for e in embedding:\n",
    "  features.append(e)\n",
    "\n",
    "# sanity check for the created data\n",
    "assert len(features)==len(sequences)\n",
    "\n",
    "print(\"Making file...\")\n",
    "h5f = h5py.File(os.path.join(prediction_folder, 'embeddings_halfprec_inference.h5'), 'w')\n",
    "for i,header in enumerate(headers):\n",
    "  h5f.create_dataset(header, data=features[i][:len(query_sequences[header])])\n",
    "h5f.close()\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fa57a-52cc-41ee-8dd6-71ac5ef6e55e",
   "metadata": {},
   "source": [
    "##### now, there is an .h5 file created in your prediction directory. We will use it to predict your proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa0f062-5f84-493f-9c0c-c95a40455a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data\n",
      "Load model\n",
      "Calculate predictions\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Q8N5K1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(headers)\n\u001b[1;32m      6\u001b[0m fasta_file\u001b[38;5;241m=\u001b[39mquery_fasta\n\u001b[0;32m----> 8\u001b[0m proteins \u001b[38;5;241m=\u001b[39m \u001b[43mBindNode23\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGCN_prediction_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m   \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membeddings_halfprec_inference.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfasta_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bind/bindPredict/bindNode23/bindNode23.py:316\u001b[0m, in \u001b[0;36mBindNode23.GCN_prediction_pipeline\u001b[0;34m(h5filepath, model_prefix, cutoff, result_folder, ids, fasta_file, ri, distance_cutoff_embd, distance_cutoff_struc)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculate predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    314\u001b[0m ml_predictor \u001b[38;5;241m=\u001b[39m MLPredictor(model)\n\u001b[0;32m--> 316\u001b[0m curr_proteins \u001b[38;5;241m=\u001b[39m \u001b[43mml_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_per_protein\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstructures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_cutoff_embd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_cutoff_embd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_cutoff_struc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_cutoff_struc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m curr_proteins\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m proteins\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/bind/bindPredict/ml_predictor.py:29\u001b[0m, in \u001b[0;36mMLPredictor.predict_per_protein\u001b[0;34m(self, ids, sequences, embeddings, labels, max_length, structures, distance_cutoff_embd, distance_cutoff_struc)\u001b[0m\n\u001b[1;32m     26\u001b[0m proteins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m in_graph, prot_id \u001b[38;5;129;01min\u001b[39;00m validation_loader:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     31\u001b[0m         prot_id \u001b[38;5;241m=\u001b[39m prot_id[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda2/envs/gcn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda2/envs/gcn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda2/envs/gcn/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda2/envs/gcn/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda2/envs/gcn/lib/python3.10/site-packages/torch_geometric/data/dataset.py:239\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/bind/bindPredict/bindNode23/dataset.py:55\u001b[0m, in \u001b[0;36mGraphDataset.get\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     53\u001b[0m     prot_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[item]\n\u001b[1;32m     54\u001b[0m     edges, edges2, attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_edge_index_and_attr_tensor(\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprot_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m     graphdata \u001b[38;5;241m=\u001b[39m Data(\n\u001b[1;32m     59\u001b[0m         x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings[prot_id]),\n\u001b[1;32m     60\u001b[0m         edge_index\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mLongTensor(edges),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m         edge_index2\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mLongTensor(edges2),\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Data necessary for forward call (from: PYG):\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    Node feature matrix with shape [num_nodes, num_node_features]. (default: None)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    edge_attr (torch.Tensor, optional) Edge feature matrix with shape [num_edges, num_edge_features]. (default: None)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    y (torch.Tensor, optional) Graph-level or node-level ground-truth labels with arbitrary shape. (default: None)\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Q8N5K1'"
     ]
    }
   ],
   "source": [
    "model_prefix=\"trained_models/trained_model\"\n",
    "cutoff=0.5\n",
    "ri=False\n",
    "result_folder=prediction_folder\n",
    "ids = list(headers)\n",
    "fasta_file=query_fasta\n",
    "\n",
    "proteins = BindNode23.GCN_prediction_pipeline(\n",
    "   os.path.join(prediction_folder, 'embeddings_halfprec_inference.h5'), model_prefix, cutoff, result_folder, ids, fasta_file, ri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2b3fb-ec95-48b6-a66a-d401e28802f9",
   "metadata": {},
   "source": [
    "#### For each protein, you will yield an output file (.bindPredict_out) with the following content:\n",
    "##### Binding prediction (b/nb), respective probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6c73527-8f07-4a8a-9f14-a47809e0ae6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein name:\n",
      "\n",
      "P32643 \n",
      "\n",
      "Position\tMetal.Proba\tMetal.Class\tNuclear.Proba\tNuclear.Class\tSmall.Proba\tSmall.Class\tAny.Class\n",
      "\n",
      "1\t\t0.002\t\tnb\t\t0.004\t\tnb\t\t0.077\t\tnb\t\tnb\n",
      "\n",
      "2\t\t0.009\t\tnb\t\t0.012\t\tnb\t\t0.354\t\tnb\t\tnb\n",
      "\n",
      "3\t\t0.029\t\tnb\t\t0.037\t\tnb\t\t0.328\t\tnb\t\tnb\n",
      "\n",
      "4\t\t0.021\t\tnb\t\t0.014\t\tnb\t\t0.428\t\tnb\t\tnb\n",
      "\n",
      "5\t\t0.005\t\tnb\t\t0.010\t\tnb\t\t0.206\t\tnb\t\tnb\n",
      "\n",
      "6\t\t0.009\t\tnb\t\t0.016\t\tnb\t\t0.277\t\tnb\t\tnb\n",
      "\n",
      "7\t\t0.011\t\tnb\t\t0.032\t\tnb\t\t0.172\t\tnb\t\tnb\n",
      "\n",
      "8\t\t0.100\t\tnb\t\t0.006\t\tnb\t\t0.332\t\tnb\t\tnb\n",
      "\n",
      "9\t\t0.046\t\tnb\t\t0.009\t\tnb\t\t0.566\t\tb\t\tb\n",
      "\n",
      "10\t\t0.038\t\tnb\t\t0.003\t\tnb\t\t0.223\t\tnb\t\tnb\n",
      "\n",
      "11\t\t0.047\t\tnb\t\t0.009\t\tnb\t\t0.280\t\tnb\t\tnb\n",
      "\n",
      "12\t\t0.048\t\tnb\t\t0.001\t\tnb\t\t0.112\t\tnb\t\tnb\n",
      "\n",
      "13\t\t0.022\t\tnb\t\t0.014\t\tnb\t\t0.286\t\tnb\t\tnb\n",
      "\n",
      "14\t\t0.124\t\tnb\t\t0.023\t\tnb\t\t0.633\t\tb\t\tb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allpredictionfiles = list(Path(prediction_folder).rglob(\"*.bindPredict_out\"))\n",
    "with open(allpredictionfiles[0], 'r') as displayFile:\n",
    "    results = displayFile.readlines()\n",
    "    \n",
    "print(\"Protein name:\\n\")\n",
    "print(allpredictionfiles[0].name.split(\".\")[0], '\\n')\n",
    "print(results[0])\n",
    "for k in range(1,15):\n",
    "    print(results[k].replace('\\t', '\\t\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65966887-e7d5-4f8a-994f-7079500da1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "CovOneBind: 298 (0.997)\n",
      "Bound: With predictions: 298, Without predictions: 1\n",
      "Not Bound: With predictions: 0, Without predictions: 0\n",
      "TP: 2711, FP: 3074, TN: 53467, FN: 3094\n",
      "Prec: 0.469 +/- 0.030, Recall: 0.517 +/- 0.033, F1: 0.438 +/- 0.024, MCC: 0.412 +/- 0.024, Acc: 0.893 +/- 0.008\n",
      "metal\n",
      "CovOneBind: 212 (0.934)\n",
      "Bound: With predictions: 109, Without predictions: 15\n",
      "Not Bound: With predictions: 103, Without predictions: 72\n",
      "TP: 341, FP: 508, TN: 49564, FN: 540\n",
      "Prec: 0.283 +/- 0.050, Recall: 0.260 +/- 0.049, F1: 0.250 +/- 0.045, MCC: 0.254 +/- 0.046, Acc: 0.977 +/- 0.004\n",
      "nucleic\n",
      "CovOneBind: 84 (0.894)\n",
      "Bound: With predictions: 55, Without predictions: 10\n",
      "Not Bound: With predictions: 29, Without predictions: 205\n",
      "TP: 445, FP: 462, TN: 19506, FN: 961\n",
      "Prec: 0.356 +/- 0.075, Recall: 0.227 +/- 0.060, F1: 0.240 +/- 0.056, MCC: 0.230 +/- 0.053, Acc: 0.920 +/- 0.014\n",
      "small\n",
      "CovOneBind: 269 (0.961)\n",
      "Bound: With predictions: 208, Without predictions: 11\n",
      "Not Bound: With predictions: 61, Without predictions: 19\n",
      "TP: 1830, FP: 2727, TN: 52280, FN: 2070\n",
      "Prec: 0.360 +/- 0.036, Recall: 0.383 +/- 0.038, F1: 0.338 +/- 0.032, MCC: 0.319 +/- 0.031, Acc: 0.912 +/- 0.007\n"
     ]
    }
   ],
   "source": [
    "from bindNode23.bindNode23 import BindNode23\n",
    "from assess_performance import PerformanceAssessment\n",
    "from config import FileSetter, FileManager, GeneralInformation\n",
    "from data_preparation import ProteinInformation\n",
    "import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "labels = ProteinInformation.get_labels(proteins.keys(), query_sequences)\n",
    "model_performances = PerformanceAssessment.combine_protein_performance(\n",
    "    proteins, cutoff, labels\n",
    ")\n",
    "PerformanceAssessment.print_performance_results(model_performances, params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfcef1-974b-44b4-b982-46f6f6ad4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code snippet created the test set subset for testing of the inference pipeline\n",
    "subset = {}\n",
    "with open(\"/home/frank/bind/bindPredict/data/development_set/uniprot_test.txt\", 'r') as idfile:\n",
    "    ides = idfile.readlines()\n",
    "for line in ides:\n",
    "    if not 'P06956' in line:\n",
    "        subset[line.rstrip()]=query_sequences[line.rstrip()]\n",
    "query_sequences = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01b79ab7-9010-4daf-a623-902bd8aba06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801783944499505"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_setsize = 1009\n",
    "ex_cob = 989.0\n",
    "cov = ex_cob/total_setsize\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "556f5713-97a9-465d-bb26-7645e3e92bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = [1]*989\n",
    "nonbindings = [0]*(1009-989)\n",
    "samplelist = bindings + nonbindings\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "def sample_with_replacement_k_times(bindlist, n=1000):\n",
    "    resultarr = np.zeros((n))\n",
    "    for bootstrap in range(n):\n",
    "        sample = random.choices(bindlist, k=1009)\n",
    "        unique, counts = np.unique(np.array(sample), return_counts=True)\n",
    "        cov = counts[1]/1009\n",
    "        #print(cov)\n",
    "        resultarr[bootstrap]=cov\n",
    "    return resultarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d10da46e-1e1f-420e-b708-03075a4e4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sample_with_replacement_k_times(samplelist)\n",
    "data = (data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34042a93-6879-4b47-9cc6-abf87b9bbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bootstrap\n",
    "bootstrap_ci = bootstrap(data, np.mean, confidence_level=0.95,\n",
    "                         random_state=1, method='percentile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94d787d8-e23a-4d9c-9254-5cd1bf4b38ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfidenceInterval(low=0.9798037661050546, high=0.9803508424182359)\n"
     ]
    }
   ],
   "source": [
    "print(bootstrap_ci.confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d5215-4409-4d77-8c3b-733c043bbcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
